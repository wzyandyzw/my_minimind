"""
实现Transformer模型,包括Attention层、FeedForward层和MoE层
"""
from torch import nn

class Attention(nn.Module):
    """
    实现Attention层
    """


class FeedForward(nn.Module):
    """
    实现FeedForward层
    """


class MoEGate(nn.Module):
    """
    实现MoE层的Gate层
    """


class MoEFeedForward(nn.Module):
    """
    实现MoE层的FeedForward层
    """
    

class Transformer(nn.Module):
    """
    实现单个Transformer层
    """